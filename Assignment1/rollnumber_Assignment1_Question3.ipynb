{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c54141",
   "metadata": {},
   "source": [
    "## Spam Email Classifier with KNN using TF-IDF scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17102e",
   "metadata": {},
   "source": [
    "1.   Assignment must be implemented in Python 3 only.\n",
    "2.   You are allowed to use libraries for data preprocessing (numpy, pandas, nltk etc) and for evaluation metrics, data visualization (matplotlib etc.).\n",
    "3.   You will be evaluated not just on the overall performance of the model and also on the experimentation with hyper parameters, data prepossessing techniques etc.\n",
    "4.   The report file must be a well documented jupyter notebook, explaining the experiments you have performed, evaluation metrics and corresponding code. The code must run and be able to reproduce the accuracies, figures/graphs etc.\n",
    "5.   For all the questions, you must create a train-validation data split and test the hyperparameter tuning on the validation set. Your jupyter notebook must reflect the same.\n",
    "6.   Strict plagiarism checking will be done. An F will be awarded for plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d34a310",
   "metadata": {},
   "source": [
    "**Task: Given an email, classify it as spam or ham**\n",
    "\n",
    "Given input text file (\"emails.txt\") containing 5572 email messages, with each row having its corresponding label (spam/ham) attached to it.\n",
    "\n",
    "This task also requires basic pre-processing of text (like removing stopwords, stemming/lemmatizing, replacing email_address with 'email-tag', etc..).\n",
    "\n",
    "You are required to find the tf-idf scores for the given data and use them to perform KNN using Cosine Similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f091428",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c87696",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d5a1fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/archit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/archit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk.corpus\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "lemmer=nltk.WordNetLemmatizer()\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef4dff",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f178f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./emails.txt\"\n",
    "data = pd.read_csv(path, sep='\\t', header=None)\n",
    "data.rename({0: 'label', 1:'mail_text'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1ef5ba",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd1733d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_up(text):\n",
    "    '''\n",
    "        convert all uppercase letters to lowercase\n",
    "        replace email address with 'email-tag'\n",
    "        stop words removal\n",
    "        lemming the words\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    if text in stop_words:\n",
    "        return False, text\n",
    "    regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    if(re.fullmatch(regex, text)):\n",
    "        return True, 'email-tag'\n",
    "    return True, lemmer.lemmatize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a55bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_pun(sentence):\n",
    "    token_list=[]\n",
    "    for i in tokenizer.tokenize(sentence):\n",
    "        a,b=del_up(i)\n",
    "        if a==True:\n",
    "            token_list.append(b)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7cf1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_text'] = data['mail_text'].apply(lambda x: tok_pun(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b766ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mail_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[nah, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                          mail_text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4        [nah, think, go, usf, life, around, though]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76767a7",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f75e6cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data['tokenized_text'], data['label'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6eb76b",
   "metadata": {},
   "source": [
    "### Train your KNN model (reuse previously iplemented model built from scratch) and test on your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22baf6b2",
   "metadata": {},
   "source": [
    "***1. Experiment with different distance measures [Euclidean distance, Manhattan distance, Hamming Distance] and compare with the Cosine Similarity distance results.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f1bb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcf6f3b1",
   "metadata": {},
   "source": [
    "***2. Explain which distance measure works best and why? Explore the distance measures and weigh their pro and cons in different application settings.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae57a01",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a99c76",
   "metadata": {},
   "source": [
    "***3. Report Mean Squared Error(MSE), Mean-Absolute-Error(MAE), R-squared (R2) score in a tabular form***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9668814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4dde8d3",
   "metadata": {},
   "source": [
    "***4. Choose different K values (k=1,3,5,7,11,17,23,28) and experiment. Plot a graph showing R2 score vs k.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e0fd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15000352",
   "metadata": {},
   "source": [
    "### Train and test Sklearn's KNN classifier model on your data (use metric which gave best results on your experimentation with built-from-scratch model.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aab7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d22aa47",
   "metadata": {},
   "source": [
    "***Compare both the models result.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7a5274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64987575",
   "metadata": {},
   "source": [
    "***What is the time complexity of training using KNN classifier?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770c106",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fad1f345",
   "metadata": {},
   "source": [
    "***What is the time complexity while testing? Is KNN a linear classifier or can it learn any boundary?***"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0daaa324",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
