{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7992a1",
   "metadata": {},
   "source": [
    "# Image Recommendation System via Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbd69cd",
   "metadata": {},
   "source": [
    "# ***Please read the instructions very carefully***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17602772",
   "metadata": {},
   "source": [
    "1.   Assignment must be implemented in Python 3 only.\n",
    "2.   You are allowed to use libraries for data preprocessing (numpy, pandas, nltk etc) and for evaluation metrics, data visualization (matplotlib etc.).\n",
    "3.   You will be evaluated not just on the overall performance of the model and also on the experimentation with hyper parameters, data prepossessing techniques etc.\n",
    "4.   ⚠️ The Assignment will be evaluated automatically. Please adhere to taking proper inputs from `config.csv` file. You can change your `config.csv` file to experiment with your code. But at the end, make sure that your outputs are corresponding to input values in `config.csv`\n",
    "5.   Strict plagiarism checking will be done. An F will be awarded for plagiarism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9abf04",
   "metadata": {},
   "source": [
    "## About the Dataset\n",
    "Behance is a community art website where users showcase and discover creative work. Each user is able to “appreciate” (equivalent to a “like” on Instagram or a “react” on Facebook) an image, indicating that they like the image. It is in the website’s best interests to show users pictures that they would like, to keep them engaged for longer. For this question, given a set of pictures that a user has already appreciated, you have to show them a new picture that they would like based on what similar users appreciated.\n",
    "\n",
    "\n",
    "<br><br>\n",
    "**The dataset has information of 1 million appreciates of 63,497 users on 178,788 items. The file Behance appreciate 1M has a triplet in each line in the form of (user id, item id, unix timestamp).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6eaf3",
   "metadata": {},
   "source": [
    "**Task: Take the inputs from the config.csv file and output the recommendations for a particular person**\n",
    "- Collaborative Filtering is a way to predict items to the user based on the the\n",
    "user’s history and the history of similar users. The similarity between users can be quantified by the number of images that both the users appreciated.\n",
    "- The images appreciated by a similar user would be the most suitable images to show a user. Since we can find the similarity between any two users, we would be able to find the “nearest” neighbours of any user, allowing us to use a KNN-based algorithm to recommend new images to a user.\n",
    "- Since people do not like seeing pictures that they have seen already. Make sure that you do not recommend pictures that a user has appreciated already.\n",
    "- Output the final response will be saved in the file named ```config['output_file']```.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a5e4f",
   "metadata": {},
   "source": [
    "**Output file format:**\n",
    "Populate the output file with images that the user has not seen of the k most\n",
    "similar users, in descending order of their similarity. Each line in the output\n",
    "file should be a duplet in the form of (item id, user id), where the user id is the\n",
    "id of the kth similar user. The order of the images corresponding to the same\n",
    "similar user would not matter. The output file would look something like this:\n",
    "```\n",
    "item_id_1_of_1st_similar_user 1st_most_similar_user_id\n",
    "item_id_2_of_1st_similar_user 1st_most_similar_user_id\n",
    "item_id_3_of_1st_similar_user 1st_most_similar_user_id\n",
    "...\n",
    "item_id_1_of_2nd_similar_user 2nd_most_similar_user_id\n",
    "item_id_2_of_2nd_similar_user 2nd_most_similar_user_id\n",
    "item_id_3_of_2nd_similar_user 2nd_most_similar_user_id\n",
    "...\n",
    "item_id_1_of_kth_similar_user kth_most_similar_user_id\n",
    "item_id_2_of_kth_similar_user kth_most_similar_user_id\n",
    "item_id_3_of_kth_similar_user kth_most_similar_user_id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0c592",
   "metadata": {},
   "source": [
    "The dataset was extracted using Behance’s API as a part of the paper\n",
    "“Vista: A visually, socially, and temporally-aware model for artistic\n",
    "recommendation, RecSys, 2016”. Check out this [Google Drive folder](https://drive.google.com/drive/folders/0B9Ck8jw-TZUEc3NlMjVXdDlPU1k?resourcekey=0-6_8ykn0o4fLc5fuTEm91xA) for\n",
    "more information about the dataset.\n",
    "\n",
    "\n",
    "Have fun! The users are waiting to see new pictures!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07d66b3",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b8072a",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f153853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ac6337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config Generation Sample Code.\n",
    "# ⚠️ Only for experimentation on your side.\n",
    "# ⚠️ Should be commented during submission.\n",
    "\n",
    "# df = pd.DataFrame(data=[{'id':276633,\n",
    "#                   'k':5,\n",
    "#                   'dataset_file':'./Behance_appreciate_1M',\n",
    "#                   'output_file':'./output.txt'}])\n",
    "# df.to_csv('config.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af3e999",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = pd.read_csv('config.csv').iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829d0147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                              0\n",
       "id                                 276633\n",
       "k                                       5\n",
       "dataset_file      ./Behance_appreciate_1M\n",
       "output_file     ./testing/output_test.txt\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d09c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = int(config['id'])\n",
    "k_value = int(config['k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10935090",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbba85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config['dataset_file'], 'r') as inFile:\n",
    "    appreciate_data = inFile.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99512e25",
   "metadata": {},
   "source": [
    "### Initialize a dictionary to store the item_ids that a user likes\n",
    "\n",
    "### Go through each line of the input file and construct the user_likes dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464b812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix,lil_matrix\n",
    "data=lil_matrix((3957261,2497166),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a539f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in appreciate_data:\n",
    "    line = line.strip()\n",
    "    user_id = int(line.split()[0])\n",
    "    item_id = int(line.split()[1])\n",
    "    data[user_id,item_id]=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e199965",
   "metadata": {},
   "source": [
    "### Use KNN after Collaborative Filtering to find nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2117df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(list1, list2):\n",
    "    \"\"\" returns intersection of two lists \"\"\"\n",
    "    val=0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] and list2[i] : \n",
    "            val+=1\n",
    "    return val\n",
    "\n",
    "def unoin(list1, list2):\n",
    "    \"\"\" returns length of union of two lists \"\"\"\n",
    "    val=0\n",
    "    for i in range(len(list1)):\n",
    "        if list1[i] or list2[i] : \n",
    "            val+=1\n",
    "    return val\n",
    "\n",
    "def jacard_similarity_score(list1, list2):\n",
    "    \"\"\" returns jacard similarity score of two lists \"\"\"\n",
    "    return intersection(list1, list2) / unoin(list1, list2)\n",
    "\n",
    "def cosine_similarity_score(list1, list2):\n",
    "    \"\"\" returns cosine similarity score of two lists \"\"\"\n",
    "    return intersection(list1, list2) / (np.sqrt(len(list1)*len(list2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d465b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacard_similarity_score(np.array(data[276633].todense())[0],np.array(data[4789].todense())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d960f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(user,k_value,user_likes):\n",
    "    \"\"\" returns an iterable object (like list or generator) \"\"\"\n",
    "    scores = {}\n",
    "    test=np.array(data[user].todense())\n",
    "    for x in range(user_likes.shape[0]):\n",
    "        if x != user:\n",
    "            scores[x] = jacard_similarity_score(test[0],np.array(data[x].todense())[0])\n",
    "    return sorted(scores.items(), key=lambda x:x[1], reverse=True)[:k_value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76f12760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2497166 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 0 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa6c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "tt=TruncatedSVD(n_components=2)\n",
    "X=tt.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dba56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1975c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/archit/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py:205: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ratio_ = exp_var / full_var\n"
     ]
    }
   ],
   "source": [
    "cc=TruncatedSVD(n_components=2)\n",
    "Y=cc.fit_transform(data[user])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59473285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.24780685]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a606b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-23 21:14:14.648380: I scann/partitioning/partitioner_factory_base.cc:71] Size of sampled dataset for training partition: 249712\n",
      "2022-01-23 21:14:15.862130: I ./scann/partitioning/kmeans_tree_partitioner_utils.h:102] PartitionerFactory ran in 1.213016294s.\n"
     ]
    }
   ],
   "source": [
    "import scann\n",
    "searcher = scann.scann_ops_pybind.builder(X, 10, \"dot_product\").tree(\n",
    "    num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
    "    2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca29b402",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error during search: Query doesn't match dataset dimsensionality",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32189/1299985103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scann/scann_ops/py/scann_ops_pybind.py\u001b[0m in \u001b[0;36msearch_batched\u001b[0;34m(self, queries, final_num_neighbors, pre_reorder_num_neighbors, leaves_to_search)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mpre_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpre_reorder_num_neighbors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpre_reorder_num_neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mleaves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleaves_to_search\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mleaves_to_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     return self.searcher.search_batched(queries, final_nn, pre_nn, leaves,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         False)\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error during search: Query doesn't match dataset dimsensionality"
     ]
    }
   ],
   "source": [
    "neighbors, distances = searcher.search_batched(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b564cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9287/922394708.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_9287/2068583131.py\u001b[0m in \u001b[0;36mneighbors\u001b[0;34m(user, k_value, user_likes)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_likes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacard_similarity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9287/855965215.py\u001b[0m in \u001b[0;36mjacard_similarity_score\u001b[0;34m(list1, list2)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjacard_similarity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"\"\" returns jacard similarity score of two lists \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0munoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine_similarity_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9287/855965215.py\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(list1, list2)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlist1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mval\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores=neighbors(user,k_value,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892c395b",
   "metadata": {},
   "source": [
    "### Open the output file to write all the lines to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428708d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outFile = open(config['output_file'], 'w')\n",
    "\n",
    "for n_user in neighbors(user,k_value,user_likes):\n",
    "    user_id = n_user[0]\n",
    "    for item_id in diff_list(user_likes[user_id],user_likes[user]):\n",
    "        outFile.write(str(item_id) + ' ' + str(user_id) + '\\n')\n",
    "\n",
    "outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2aea57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
